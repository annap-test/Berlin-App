{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# Playgrounds Labels â€” Neighborhoods and Districts\n","Self-contained notebook to compute playground density labels and export CSVs:\n","- neighborhoods: [district, neighborhood, hashtags, source]\n","- districts: [district, hashtags, source]"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "# Config (resolve project root so paths work from this notebook)\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT/'data').exists():\n",
    "    ROOT = ROOT.parent\n",
    "if not (ROOT/'data').exists():\n",
    "    raise FileNotFoundError(f\"Couldn't locate 'data' directory from {Path.cwd()}\")\n",
    "RAW_DIR = ROOT/'data'/'raw'\n",
    "NEI_PATH = ROOT/'data'/'neighborhoods.geojson'\n",
    "OUT_DIR = Path('outputs'); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLAY_CSV = RAW_DIR/'playgrounds.csv'\n",
    "\n",
    "def ensure_wgs84(gdf):\n",
    "    if gdf.crs is None: return gdf.set_crs(4326)\n",
    "    return gdf.to_crs(4326) if gdf.crs.to_epsg()!=4326 else gdf\n",
    "def compute_area_km2(gdf):\n",
    "    gutm = ensure_wgs84(gdf).to_crs(25833)\n",
    "    gdf['area_km2'] = (gutm.geometry.area/1e6).values\n",
    "    gdf['area_eff_km2'] = gdf['area_km2'].clip(lower=0.20)\n",
    "    return gdf\n",
    "def playgrounds_tag(label):\n",
    "    lab = str(label).strip().lower()\n",
    "    mapping = {\n",
    "        'below average': '#low_playground_density',\n",
    "        'average': '#average_playground_density',\n",
    "        'above average': '#high_playground_density',\n",
    "    }\n",
    "    return mapping.get(lab, '#average_playground_density')\n",
    "\n",
    "GDF = compute_area_km2(ensure_wgs84(gpd.read_file(NEI_PATH)))\n",
    "df = pd.read_csv(PLAY_CSV)\n",
    "mask = df['green_area_type'].astype(str).str.lower().str.contains('spielplatz', na=False)\n",
    "cnt = df.loc[mask].groupby(['district_id','neighborhood'], dropna=False).size().rename('n_playgrounds').reset_index()\n",
    "nei = GDF[['district_id','district','neighborhood','area_eff_km2']].merge(cnt, on=['district_id','neighborhood'], how='left').fillna({'n_playgrounds':0})\n",
    "nei['playgrounds_per_km2'] = (nei['n_playgrounds']/nei['area_eff_km2']).replace([np.inf,-np.inf], np.nan)\n",
    "med = np.nanmedian(nei['playgrounds_per_km2']); l,u = med-0.30, med+0.30\n",
    "nei['playgrounds_density_label'] = nei['playgrounds_per_km2'].apply(lambda v: 'below average' if (not np.isnan(v) and v<l) else ('above average' if (not np.isnan(v) and v>u) else 'average'))\n",
    "nei_out = pd.DataFrame({\n",
    "    'district': nei['district'],\n",
    "    'neighborhood': nei['neighborhood'],\n",
    "    'hashtags': [playgrounds_tag(v) for v in nei['playgrounds_density_label']],\n",
    "    'source': 'playgrounds.ipynb:rule-based'\n",
    "})\n",
    "nei_out.to_csv(OUT_DIR/'neighborhood_labels_playgrounds.csv', index=False)\n",
    "# Append to combined neighborhoods long table (idempotent)\n",
    "nei_long_path = OUT_DIR/'berlin_neighborhoods_labels_long.csv'\n",
    "if nei_long_path.exists():\n",
    "    _old = pd.read_csv(nei_long_path)\n",
    "    _new = pd.concat([_old, nei_out], ignore_index=True)\n",
    "else:\n",
    "    _new = nei_out.copy()\n",
    "_new = _new.drop_duplicates(subset=['district','neighborhood','hashtags','source'])\n",
    "_new.to_csv(nei_long_path, index=False)\n",
    "\n",
    "dist = nei.groupby(['district'], dropna=False)[['n_playgrounds','area_eff_km2']].sum().reset_index()\n",
    "dist['playgrounds_per_km2'] = (dist['n_playgrounds']/dist['area_eff_km2']).replace([np.inf,-np.inf], np.nan)\n",
    "medd = np.nanmedian(dist['playgrounds_per_km2']); ld,ud = medd-0.30, medd+0.30\n",
    "dist['playgrounds_density_label'] = dist['playgrounds_per_km2'].apply(lambda v: 'below average' if (not np.isnan(v) and v<ld) else ('above average' if (not np.isnan(v) and v>ud) else 'average'))\n",
    "dist_out = pd.DataFrame({\n",
    "    'district': dist['district'],\n",
    "    'hashtags': [playgrounds_tag(v) for v in dist['playgrounds_density_label']],\n",
    "    'source': 'playgrounds.ipynb:rule-based'\n",
    "})\n",
    "dist_out.to_csv(OUT_DIR/'district_labels_playgrounds.csv', index=False)\n",
    "# Append to combined districts long table (idempotent)\n",
    "dist_long_path = OUT_DIR/'berlin_districts_labels_long.csv'\n",
    "if dist_long_path.exists():\n",
    "    _old = pd.read_csv(dist_long_path)\n",
    "    _new = pd.concat([_old, dist_out], ignore_index=True)\n",
    "else:\n",
    "    _new = dist_out.copy()\n",
    "_new = _new.drop_duplicates(subset=['district','hashtags','source'])\n",
    "_new.to_csv(dist_long_path, index=False)\n",
    "\n",
    "# Update/append to wide tables for Streamlit (idempotent)\n",
    "# Neighborhoods wide\n",
    "nei_wide_cols = ['district','neighborhood','n_playgrounds','playgrounds_per_km2','playgrounds_density_label']\n",
    "nei_wide = nei[nei_wide_cols].copy()\n",
    "nei_wide_path = OUT_DIR/'berlin_neighborhoods_labels_wide.csv'\n",
    "if nei_wide_path.exists():\n",
    "    _w = pd.read_csv(nei_wide_path)\n",
    "    keys = ['district','neighborhood']\n",
    "    _w = _w.merge(nei_wide, on=keys, how='outer', suffixes=('', '_new'))\n",
    "    for c in ['n_playgrounds','playgrounds_per_km2','playgrounds_density_label']:\n",
    "        if c+'_new' in _w.columns:\n",
    "            _w[c] = _w[c].combine_first(_w[c+'_new'])\n",
    "            _w = _w.drop(columns=[c+'_new'])\n",
    "else:\n",
    "    _w = nei_wide\n",
    "_w.to_csv(nei_wide_path, index=False)\n",
    "\n",
    "# Districts wide\n",
    "dist_wide_cols = ['district','n_playgrounds','playgrounds_per_km2','playgrounds_density_label']\n",
    "dist_wide = dist[dist_wide_cols].copy()\n",
    "dist_wide_path = OUT_DIR/'berlin_districts_labels_wide.csv'\n",
    "if dist_wide_path.exists():\n",
    "    _wd = pd.read_csv(dist_wide_path)\n",
    "    _wd = _wd.merge(dist_wide, on=['district'], how='outer', suffixes=('', '_new'))\n",
    "    for c in ['n_playgrounds','playgrounds_per_km2','playgrounds_density_label']:\n",
    "        if c+'_new' in _wd.columns:\n",
    "            _wd[c] = _wd[c].combine_first(_wd[c+'_new'])\n",
    "            _wd = _wd.drop(columns=[c+'_new'])\n",
    "else:\n",
    "    _wd = dist_wide\n",
    "_wd.to_csv(dist_wide_path, index=False)\n",
    "\n",
    "CAT = {'above average':'#1a9641','average':'#a6d96a','below average':'#fee08b'}\n",
    "def style_cat(f, col):\n",
    "    v = f['properties'].get(col); return {'fillColor': CAT.get(str(v).lower() if isinstance(v,str) else v, '#cccccc'), 'color':'#555','weight':0.5, 'fillOpacity':0.75}\n",
    "m_nei = folium.Map(location=[52.52,13.405], zoom_start=10, tiles='cartodbpositron')\n",
    "g_nei = GDF.merge(nei[['district','neighborhood','playgrounds_density_label']], on=['district','neighborhood'])\n",
    "folium.GeoJson(g_nei, style_function=lambda f, c='playgrounds_density_label': style_cat(f,c), tooltip=folium.GeoJsonTooltip(fields=['neighborhood','district','playgrounds_density_label'])).add_to(m_nei)\n",
    "m_nei.save(str(OUT_DIR/'playgrounds_map_neighborhoods.html'))\n",
    "m_dist = folium.Map(location=[52.52,13.405], zoom_start=10, tiles='cartodbpositron')\n",
    "dist_polys = GDF.dissolve(by=['district'], as_index=False)\n",
    "g_dist = dist_polys.merge(dist[['district','playgrounds_density_label']], on='district')\n",
    "folium.GeoJson(g_dist, style_function=lambda f, c='playgrounds_density_label': style_cat(f,c), tooltip=folium.GeoJsonTooltip(fields=['district','playgrounds_density_label'])).add_to(m_dist)\n",
    "m_dist.save(str(OUT_DIR/'playgrounds_map_districts.html'))\n"
  ]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
